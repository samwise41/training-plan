import json
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# --- CONFIG ---
# Get the absolute path of the repository root (one level up from this script)
REPO_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Input: The JSON file generated by the previous step (migrate_weekly_data.py)
# Note: Ensure migrate_weekly_data.py is actually saving this file to this location.
# If migrate_weekly_data.py saves to 'python/my_garmin_data_ALL.json', use that.
DATA_FILE = os.path.join(REPO_ROOT, 'python', 'my_garmin_data_ALL.json')

# Output: The briefing file in the repo root
OUTPUT_FILE = os.path.join(REPO_ROOT, 'COACH_BRIEFING.md')

# --- DEFINITIONS ---
METRICS = {
    'aerobic_efficiency': {'unit': 'EF', 'good': 'up', 'range': (1.3, 1.7)},
    'torque_efficiency':  {'unit': 'W/RPM', 'good': 'up', 'range': (2.5, 3.5)},
    'run_economy':        {'unit': 'm/beat', 'good': 'up', 'range': (1.0, 1.6)},
    'run_stiffness':      {'unit': 'ratio', 'good': 'up', 'range': (0.75, 0.95)},
    'ground_contact':     {'unit': 'ms', 'good': 'down', 'range': (220, 260)},
    'vertical_osc':       {'unit': 'cm', 'good': 'down', 'range': (6.0, 9.0)},
    'vo2_max':            {'unit': 'ml/kg', 'good': 'up', 'range': (45, 60)}
}

def load_data():
    if not os.path.exists(DATA_FILE):
        print(f"Error: Data file not found at {DATA_FILE}")
        # Return empty DF to allow script to run and produce "No Data" report
        return pd.DataFrame()
        
    with open(DATA_FILE, 'r') as f:
        data = json.load(f)
    return pd.DataFrame(data)

def calculate_slope(series):
    if len(series) < 3: return 0.0
    y = series.values
    x = np.arange(len(y))
    slope = np.polyfit(x, y, 1)[0]
    return slope

def determine_trend(slope, good_direction):
    if abs(slope) < 0.001: return "‚û°Ô∏è Stable"
    is_up = slope > 0
    if good_direction == 'up':
        return "‚ÜóÔ∏è Improving" if is_up else "‚ÜòÔ∏è Declining"
    else: 
        return "‚ÜóÔ∏è Worsening" if is_up else "‚ÜòÔ∏è Improving"

def analyze_metric(df, col_name, config):
    now = datetime.now()
    results = {}
    
    if col_name not in df.columns:
        return {'30d': 'No Data', '90d': 'No Data', '6m': 'No Data'}

    df_clean = df.dropna(subset=[col_name]).sort_values('startTimeLocal')
    
    for days in [30, 90, 180]:
        cutoff = now - timedelta(days=days)
        subset = df_clean[df_clean['startTime_dt'] >= cutoff]
        
        if len(subset) < 3:
            results[f'{days}d'] = "Not enough data"
            continue

        slope = calculate_slope(subset[col_name])
        trend_desc = determine_trend(slope, config['good'])
        avg_val = subset[col_name].mean()
        
        results[f'{days}d'] = f"{trend_desc} (Avg: {avg_val:.2f})"
        if days == 30: results['current'] = avg_val

    return results

def main():
    print("Starting Trend Analysis...")
    print(f"Looking for data at: {DATA_FILE}")
    
    df = load_data()
    
    if df.empty:
        print("Dataframe is empty. Creating error report.")
        with open(OUTPUT_FILE, 'w') as f:
            f.write("# Error: No Data Found\n")
            f.write(f"Could not locate source data at {DATA_FILE}")
        return

    # Data Prep
    df['startTime_dt'] = pd.to_datetime(df['startTimeLocal'])
    
    # Calculate Metrics (Safe Access)
    df['aerobic_efficiency'] = np.where(
        (df['activityType'].apply(lambda x: x.get('typeKey') in ['virtual_ride', 'road_biking'])) & (df['averageHR'] > 0),
        df['avgPower'] / df['averageHR'], np.nan
    )
    
    df['torque_efficiency'] = np.where(
        (df['activityType'].apply(lambda x: x.get('typeKey') == 'virtual_ride')) & (df['averageBikingCadenceInRevPerMinute'] > 0),
        df['avgPower'] / df['averageBikingCadenceInRevPerMinute'], np.nan
    )

    df['run_speed_m_min'] = df['averageSpeed'] * 60
    df['run_economy'] = np.where(
        (df['activityType'].apply(lambda x: x.get('typeKey') == 'running')) & (df['averageHR'] > 0),
        df['run_speed_m_min'] / df['averageHR'], np.nan
    )

    df['run_stiffness'] = np.where(
        (df['activityType'].apply(lambda x: x.get('typeKey') == 'running')) & (df['avgPower'] > 0),
        (df['averageSpeed'] * 100) / df['avgPower'], np.nan
    )

    df['ground_contact'] = df.get('avgGroundContactTime', np.nan)
    df['vertical_osc'] = df.get('avgVerticalOscillation', np.nan)
    df['vo2_max'] = df.get('vO2MaxValue', np.nan)

    # Generate Report
    print(f"Writing briefing to: {OUTPUT_FILE}")
    with open(OUTPUT_FILE, 'w') as f:
        f.write("# ü§ñ AI Coach Context Briefing\n")
        f.write(f"**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
        
        f.write("## 1. Physiological Trends\n")
        f.write("| Metric | Target | 30d Trend | 90d Trend | 6m Trend | Status |\n")
        f.write("| :--- | :--- | :--- | :--- | :--- | :--- |\n")

        alerts = []
        for key, conf in METRICS.items():
            stats = analyze_metric(df, key, conf)
            current = stats.get('current', 0)
            r_min, r_max = conf['range']
            
            status_icon = "‚úÖ"
            if current < r_min: 
                status_icon = "‚ö†Ô∏è Low"
                if conf['good'] == 'up': alerts.append(f"**{key}** is {current:.2f} (Target: >{r_min}).")
            elif current > r_max: 
                status_icon = "‚ö†Ô∏è High"
                if conf['good'] == 'down': alerts.append(f"**{key}** is {current:.2f} (Target: <{r_max}).")
            
            f.write(f"| **{key.replace('_', ' ').title()}** | {r_min}-{r_max} {conf['unit']} | {stats.get('30d', '--')} | {stats.get('90d', '--')} | {stats.get('6m', '--')} | {status_icon} |\n")

        f.write("\n## 2. Actionable Alerts\n")
        if alerts:
            for a in alerts: f.write(f"- {a}\n")
        else:
            f.write("- All systems Nominal.\n")
            
    print("Briefing generated successfully.")

if __name__ == "__main__":
    main()
